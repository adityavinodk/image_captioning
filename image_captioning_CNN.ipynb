{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from cnn_model import ImageClassificationModel\n",
    "\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pickle as pkl\n",
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_annotations.json', 'r') as file:\n",
<<<<<<< HEAD
    "    train_annotations = json.load(file)\n",
    "\n",
    "# # with open('validation_annotations.json', 'r') as file:\n",
    "# #     validation_annotations = json.load(file)\n",
    "# cb = Callback()\n",
    "# from tensorflow.python.client import device_lib\n",
    "# with tf.device('/cpu:0'):\n",
    "#     print(device_lib.list_local_devices())\n",
    "# print(tf.test.gpu_device_name())\n",
    "# tf.test.is_gpu_available(\n",
    "#     cuda_only=True,\n",
    "#     min_cuda_compute_capability=None\n",
    "# )\n",
    "# del train_annotations\n",
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
    "#         device_count = {'GPU': 0}\n",
    "#     ))\n",
    "# sess.list_devices()"
=======
    "    train_annotations = json.load(file)"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128,128)\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "nb_train_samples = len(os.listdir(train_data_dir))\n",
    "nb_validation_samples = len(os.listdir(validation_data_dir))\n",
    "epochs = 50\n",
    "batch_size = 60"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 4.48 kB </td> <td> 1.12 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (80,) </td> <td> (20,) </td></tr>\n",
       "    <tr><th> Count </th><td> 5 Tasks </td><td> 4 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> <U14 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"76\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"26\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"26\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"26\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,26.512734 0.000000,26.512734\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"46.512734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >80</text>\n",
       "  <text x=\"140.000000\" y=\"13.256367\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,13.256367)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(80,), dtype=<U14, chunksize=(20,), chunktype=numpy.ndarray>"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 6,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# with open('annotations/instances_train2014.json','r') as file:\n",
    "#     instances = json.load(file)\n",
    "\n",
    "# labels = np.array([category['name'] for category in instances['categories']])\n",
    "# labels = da.from_array(labels, chunks = (20))\n",
    "# labels.to_zarr('labels.zarr')\n",
    "labels = da.from_zarr('labels.zarr')\n",
    "labels\n",
    "# del instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagePaths = list(paths.list_images('train'))\n",
    "# shape = (len(imagePaths),)+target_size+(3,)\n",
    "# train_x = np.zeros(shape=shape, dtype=np.float16)\n",
    "# train_y = []\n",
    "# for i in tqdm(range(len(imagePaths))):\n",
    "#     imagePath = imagePaths[i]\n",
    "#     image = Image.open(imagePath)\n",
    "#     image = image.resize(size=target_size, resample=Image.LANCZOS)\n",
    "#     image = np.array(image)\n",
    "#     if (len(image.shape) == 2):\n",
    "#         image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "#     # print(image.shape)\n",
    "#     train_x[i]=image\n",
    "#     labels = set()\n",
    "#     for category in train_annotations[imagePath.split(os.path.sep)[-1]]['categories']: labels.add(category)\n",
    "#     train_y.append(list(labels))"
=======
    "if 'labels.zarr' not in os.listdir('.'):\n",
    "    with open('annotations/instances_train2014.json','r') as file:\n",
    "        instances = json.load(file)\n",
    "    labels = np.array([category['name'] for category in instances['categories']])\n",
    "    labels = da.from_array(labels, chunks = (20))\n",
    "    labels.to_zarr('labels.zarr')\n",
    "    del instances\n",
    "\n",
    "labels = da.from_zarr('labels.zarr')\n",
    "labels"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
<<<<<<< HEAD
    "with tf.device('/cpu:0'):\n",
    "#     train_x = np.load('train_x_128.npy', allow_pickle=True).astype('uint8')\n",
    "#     train_x = train_x.astype(int)\n",
    "#     train_x = train_x.astype('uint8')\n",
    "#     train_x = da.from_array(train_x, chunks = (827,128,128,3))\n",
    "#     train_x.to_zarr(\"train_x_128_dask.zarr\")\n",
    "    train_x = da.from_zarr(\"train_x_128_dask.zarr\")\n",
    "#     train_y = np.load('train_y.npy', allow_pickle=True)\n",
    "#     train_y = np.array(train_y)\n",
    "#     mlb = MultiLabelBinarizer(labels)\n",
    "#     train_y = mlb.fit_transform(train_y)\n",
    "    train_y = da.from_zarr(\"train_y_dask.zarr\")"
=======
    "if \"train_x_128_dask.zarr\" in os.listdir('.') and \"train_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        train_x = da.from_zarr(\"train_x_128_dask.zarr\")\n",
    "        train_y = da.from_zarr(\"train_y_dask.zarr\")\n",
    "\n",
    "else: \n",
    "    train_x = np.load('train_x_128.npy', allow_pickle=True)\n",
    "    train_x = train_x.astype('uint8')\n",
    "    train_x = da.from_array(train_x, chunks = (827,128,128,3))\n",
    "    train_x.to_zarr(\"train_x_128_dask.zarr\")\n",
    "    \n",
    "    train_y = np.load('train_y.npy', allow_pickle=True)\n",
    "    train_y = np.array(train_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels)\n",
    "    train_y = mlb.fit_transform(train_y)\n",
    "    \n",
    "    train_y = train_y.astype('uint8')\n",
    "    train_y = da.from_array(train_y, chunks = (827,128,128,3))\n",
    "    train_y.to_zarr(\"train_y_128_dask.zarr\")"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# imagePaths = list(paths.list_images('validation'))\n",
    "# shape = (len(imagePaths),)+target_size+(3,)\n",
    "# validation_x = np.zeros(shape=shape, dtype=np.float16)\n",
    "# validation_y = []\n",
    "# for i in tqdm(range(len(imagePaths))):\n",
    "#     imagePath = imagePaths[i]\n",
    "#     image = Image.open(imagePath)\n",
    "#     image = image.resize(size=target_size, resample=Image.LANCZOS)\n",
    "#     image = np.array(image)\n",
    "#     if (len(image.shape) == 2):\n",
    "#         image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "#     # print(image.shape)\n",
    "#     validation_x[i]=image\n",
    "#     labels = set()\n",
    "#     for category in validation_annotations[imagePaths[i].split(os.path.sep)[-1]]['categories']: labels.add(category)\n",
    "#     validation_y.append(list(labels))\n",
    "# train_x.to_zarr(\"train_x_244_dask.zarr\")"
=======
    "if \"validation_x_128_dask.zarr\" in os.listdir('.') and \"validation_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        validation_x = da.from_zarr(\"validation_x_128_dask.zarr\")\n",
    "        validation_y = da.from_zarr(\"validation_y_dask.zarr\")\n",
    "\n",
    "else: \n",
    "    validation_x = np.load('validation_x_128.npy', allow_pickle=True)\n",
    "    validation_x = validation_x.astype('uint8')\n",
    "    validation_x = da.from_array(validation_x, chunks = (827,128,128,3))\n",
    "    validation_x.to_zarr(\"validation_x_128_dask.zarr\")\n",
    "    \n",
    "    validation_y = np.load('validation_y.npy', allow_pickle=True)\n",
    "    validation_y = np.array(validation_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels)\n",
    "    validation_y = mlb.fit_transform(validation_y)\n",
    "    \n",
    "    validation_y = validation_y.astype('uint8')\n",
    "    validation_y = da.from_array(validation_y, chunks = (827,128,128,3))\n",
    "    validation_y.to_zarr(\"validation_y_128_dask.zarr\")"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
<<<<<<< HEAD
    "with tf.device('/cpu:0'):\n",
    "#     validation_x = np.load('validation_x_128.npy', allow_pickle=True)#).astype(int)).astype('uint8')\n",
    "#     validation_x = da.from_array(validation_x, chunks = (400,128,128,3))\n",
    "#     validation_x.to_zarr('validation_x_128_dask.zarr')\n",
    "#     validation_y = np.load('validation_y.npy', allow_pickle=True)\n",
    "#     validation_y = np.array(validation_y)\n",
    "#     mlb = MultiLabelBinarizer(labels)\n",
    "#     validation_y = mlb.fit_transform(validation_y)\n",
    "    validation_x = da.from_zarr(\"validation_x_128_dask.zarr\")\n",
    "    validation_y = da.from_zarr(\"validation_y_dask.zarr\")"
=======
    "train_x"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 2.44 GB </td> <td> 40.65 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (49620, 128, 128, 3) </td> <td> (827, 128, 128, 3) </td></tr>\n",
       "    <tr><th> Count </th><td> 61 Tasks </td><td> 60 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> uint8 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"470\" height=\"90\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"2\" y1=\"0\" x2=\"2\" y2=\"25\" />\n",
       "  <line x1=\"4\" y1=\"0\" x2=\"4\" y2=\"25\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"25\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"25\" />\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"25\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"25\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"16\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"20\" y1=\"0\" x2=\"20\" y2=\"25\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"25\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"25\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"25\" />\n",
       "  <line x1=\"28\" y1=\"0\" x2=\"28\" y2=\"25\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"25\" />\n",
       "  <line x1=\"32\" y1=\"0\" x2=\"32\" y2=\"25\" />\n",
       "  <line x1=\"34\" y1=\"0\" x2=\"34\" y2=\"25\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"25\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"38\" y2=\"25\" />\n",
       "  <line x1=\"40\" y1=\"0\" x2=\"40\" y2=\"25\" />\n",
       "  <line x1=\"42\" y1=\"0\" x2=\"42\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"46\" y1=\"0\" x2=\"46\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"50\" y1=\"0\" x2=\"50\" y2=\"25\" />\n",
       "  <line x1=\"52\" y1=\"0\" x2=\"52\" y2=\"25\" />\n",
       "  <line x1=\"54\" y1=\"0\" x2=\"54\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"58\" y1=\"0\" x2=\"58\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"62\" y1=\"0\" x2=\"62\" y2=\"25\" />\n",
       "  <line x1=\"64\" y1=\"0\" x2=\"64\" y2=\"25\" />\n",
       "  <line x1=\"66\" y1=\"0\" x2=\"66\" y2=\"25\" />\n",
       "  <line x1=\"68\" y1=\"0\" x2=\"68\" y2=\"25\" />\n",
       "  <line x1=\"70\" y1=\"0\" x2=\"70\" y2=\"25\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"25\" />\n",
       "  <line x1=\"74\" y1=\"0\" x2=\"74\" y2=\"25\" />\n",
       "  <line x1=\"76\" y1=\"0\" x2=\"76\" y2=\"25\" />\n",
       "  <line x1=\"78\" y1=\"0\" x2=\"78\" y2=\"25\" />\n",
       "  <line x1=\"80\" y1=\"0\" x2=\"80\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"25\" />\n",
       "  <line x1=\"86\" y1=\"0\" x2=\"86\" y2=\"25\" />\n",
       "  <line x1=\"88\" y1=\"0\" x2=\"88\" y2=\"25\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"25\" />\n",
       "  <line x1=\"92\" y1=\"0\" x2=\"92\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"94\" y2=\"25\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"25\" />\n",
       "  <line x1=\"98\" y1=\"0\" x2=\"98\" y2=\"25\" />\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"100\" y2=\"25\" />\n",
       "  <line x1=\"102\" y1=\"0\" x2=\"102\" y2=\"25\" />\n",
       "  <line x1=\"104\" y1=\"0\" x2=\"104\" y2=\"25\" />\n",
       "  <line x1=\"106\" y1=\"0\" x2=\"106\" y2=\"25\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
       "  <line x1=\"110\" y1=\"0\" x2=\"110\" y2=\"25\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"25\" />\n",
       "  <line x1=\"114\" y1=\"0\" x2=\"114\" y2=\"25\" />\n",
       "  <line x1=\"116\" y1=\"0\" x2=\"116\" y2=\"25\" />\n",
       "  <line x1=\"118\" y1=\"0\" x2=\"118\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,25.412617 0.000000,25.412617\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >49620</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"204\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"190\" y1=\"25\" x2=\"204\" y2=\"40\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"190\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"204\" y1=\"14\" x2=\"204\" y2=\"40\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.000000,0.000000 204.948598,14.948598 204.948598,40.361214 190.000000,25.412617\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"215\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"204\" y1=\"14\" x2=\"230\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"190\" y1=\"0\" x2=\"204\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"215\" y1=\"0\" x2=\"230\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"190.000000,0.000000 215.412617,0.000000 230.361214,14.948598 204.948598,14.948598\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"204\" y1=\"14\" x2=\"230\" y2=\"14\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"204\" y1=\"40\" x2=\"230\" y2=\"40\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"204\" y1=\"14\" x2=\"204\" y2=\"40\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"230\" y1=\"14\" x2=\"230\" y2=\"40\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"204.948598,14.948598 230.361214,14.948598 230.361214,40.361214 204.948598,40.361214\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"217.654906\" y=\"60.361214\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >3</text>\n",
       "  <text x=\"250.361214\" y=\"27.654906\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,250.361214,27.654906)\">128</text>\n",
       "  <text x=\"187.474299\" y=\"52.886915\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,187.474299,52.886915)\">128</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(49620, 128, 128, 3), dtype=uint8, chunksize=(827, 128, 128, 3), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=25, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "if 'best_model.h5' in os.listdir():\n",
    "    model = load_model('best_model.h5')\n",
    "    model.load_weights('best_ modelw.h5')\n",
    "else:\n",
    "    model = ImageClassificationModel.build(target_size[0], target_size[1], len(labels), 'softmax')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.9, beta_2=0.95), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7701 - accuracy: 0.5261\n",
      "Epoch 00001: val_loss improved from inf to 9.88083, saving model to best_model_loss.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51970, saving model to best_model_acc.h5\n",
      "827/827 [==============================] - 233s 281ms/step - loss: 8.7685 - accuracy: 0.5263 - val_loss: 9.8808 - val_accuracy: 0.5197\n",
      "Epoch 2/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7731 - accuracy: 0.5275\n",
      "Epoch 00002: val_loss improved from 9.88083 to 9.83895, saving model to best_model_loss.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.51970\n",
      "827/827 [==============================] - 221s 267ms/step - loss: 8.7737 - accuracy: 0.5275 - val_loss: 9.8390 - val_accuracy: 0.4847\n",
      "Epoch 3/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7667 - accuracy: 0.5274\n",
      "Epoch 00003: val_loss improved from 9.83895 to 9.12999, saving model to best_model_loss.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.51970\n",
      "827/827 [==============================] - 225s 273ms/step - loss: 8.7684 - accuracy: 0.5273 - val_loss: 9.1300 - val_accuracy: 0.5108\n",
      "Epoch 4/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7664 - accuracy: 0.5262\n",
      "Epoch 00004: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.51970\n",
      "827/827 [==============================] - 218s 263ms/step - loss: 8.7667 - accuracy: 0.5262 - val_loss: 9.7960 - val_accuracy: 0.4938\n",
      "Epoch 5/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7726 - accuracy: 0.5284\n",
      "Epoch 00005: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.51970\n",
      "827/827 [==============================] - 226s 274ms/step - loss: 8.7721 - accuracy: 0.5284 - val_loss: 10.3619 - val_accuracy: 0.5184\n",
      "Epoch 6/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7729 - accuracy: 0.5274\n",
      "Epoch 00006: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.51970 to 0.52588, saving model to best_model_acc.h5\n",
      "827/827 [==============================] - 223s 270ms/step - loss: 8.7749 - accuracy: 0.5275 - val_loss: 10.4260 - val_accuracy: 0.5259\n",
      "Epoch 7/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7737 - accuracy: 0.5254\n",
      "Epoch 00007: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.52588 to 0.54061, saving model to best_model_acc.h5\n",
      "827/827 [==============================] - 229s 276ms/step - loss: 8.7746 - accuracy: 0.5255 - val_loss: 9.3772 - val_accuracy: 0.5406\n",
      "Epoch 8/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7735 - accuracy: 0.5265\n",
      "Epoch 00008: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.54061\n",
      "827/827 [==============================] - 223s 269ms/step - loss: 8.7734 - accuracy: 0.5265 - val_loss: 10.5542 - val_accuracy: 0.4913\n",
      "Epoch 9/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7745 - accuracy: 0.5271\n",
      "Epoch 00009: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.54061\n",
      "827/827 [==============================] - 228s 276ms/step - loss: 8.7745 - accuracy: 0.5271 - val_loss: 10.3509 - val_accuracy: 0.4943\n",
      "Epoch 10/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7576 - accuracy: 0.5250\n",
      "Epoch 00010: val_loss did not improve from 9.12999\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.54061\n",
      "827/827 [==============================] - 224s 271ms/step - loss: 8.7581 - accuracy: 0.5249 - val_loss: 9.9018 - val_accuracy: 0.5058\n",
      "Epoch 11/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7734 - accuracy: 0.5269\n",
      "Epoch 00011: val_loss improved from 9.12999 to 9.11686, saving model to best_model_loss.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.54061\n",
      "827/827 [==============================] - 230s 279ms/step - loss: 8.7728 - accuracy: 0.5270 - val_loss: 9.1169 - val_accuracy: 0.4913\n",
      "Epoch 12/50\n",
      "826/827 [============================>.] - ETA: 0s - loss: 8.7659 - accuracy: 0.5285\n",
      "Epoch 00012: val_loss did not improve from 9.11686\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.54061\n",
      "827/827 [==============================] - 222s 269ms/step - loss: 8.7674 - accuracy: 0.5285 - val_loss: 9.6092 - val_accuracy: 0.5169\n",
      "Epoch 13/50\n",
      " 90/827 [==>...........................] - ETA: 3:03 - loss: 8.8313 - accuracy: 0.5248"
     ]
=======
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    stop_early = EarlyStopping(monitor='val_loss',patience = 20)\n",
<<<<<<< HEAD
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',patience = 20, factor=0.2, min_lr = 0.0001)\n",
    "    ModelCheck1    =ModelCheckpoint('best_model_loss.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "#     ModelCheck2    =ModelCheckpoint('best_model_acc.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks = [stop_early, reduceLR, ModelCheck1]\n",
=======
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',paitence = 20, factor=0.2, min_lr = 0.0001)\n",
    "    ModelCheck1 = ModelCheckpoint('best_model_loss.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    ModelCheck2 = ModelCheckpoint('best_model_acc.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks = [stop_early, reduceLR, ModelCheck1,ModelCheck2]\n",
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
    "    model.fit_generator(\n",
    "        train_datagen.flow(train_x, train_y, batch_size= batch_size),\n",
    "        steps_per_epoch = nb_train_samples//batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data=validation_datagen.flow(validation_x, validation_y, batch_size=batch_size),\n",
    "        validation_steps = nb_validation_samples//batch_size,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": null,
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model.save_weights(\"best_modelw.h5\")\n",
    "# f = open('mlb.pickle', 'wb')\n",
    "# f.write(pkl.dumps(mlb))\n",
    "# f.close()"
=======
    "model.save_weights(\"best_modelw.h5\")"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')\n",
    "# type(model_1)"
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9387c74797ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model.h5')"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "traffic light\n"
     ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
    }
   ],
   "source": [
    "img = Image.open('test/COCO_train2014_000000543689.jpg')# image extension *.png,*.jpg\n",
    "img.show()\n",
    "img = img.resize((128,128), Image.ANTIALIAS)\n",
    "arr = np.array(img)\n",
    "arr=np.expand_dims(arr,0)\n",
    "arr=arr/255\n",
    "proba = model.predict(arr)[0]\n",
    "proba= (proba*1000).astype(int)\n",
    "for x in range(len(proba)):\n",
    "    if proba[x] >100:\n",
    "        proba[x]=1\n",
    "    elif proba[x] > 50:\n",
    "        proba[x] = 0.5\n",
    "    else:\n",
    "        proba[x]=0\n",
    "for i in range(len(proba)):\n",
    "    if(proba[i]==1):\n",
    "        print(labels[i])\n",
    "    elif proba[i]==0.5:\n",
    "        print(\"Probably -> \", labels[i])"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
=======
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
<<<<<<< HEAD
}
=======
}
>>>>>>> 53fa87cc674829694f016daadfa6ca4ce5855718
