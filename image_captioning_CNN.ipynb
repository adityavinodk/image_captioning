{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"0\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from cnn_model import ImageClassificationModel\n",
    "\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pickle as pkl\n",
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_annotations.json', 'r') as file:\n",
    "    train_annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128,128)\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "nb_train_samples = len(os.listdir(train_data_dir))\n",
    "nb_validation_samples = len(os.listdir(validation_data_dir))\n",
    "epochs = 50\n",
    "batch_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 4.48 kB </td> <td> 1.12 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (80,) </td> <td> (20,) </td></tr>\n",
       "    <tr><th> Count </th><td> 5 Tasks </td><td> 4 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> <U14 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"76\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"26\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"26\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"26\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"26\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"26\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,26.512734 0.000000,26.512734\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"46.512734\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >80</text>\n",
       "  <text x=\"140.000000\" y=\"13.256367\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,13.256367)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<from-zarr, shape=(80,), dtype=<U14, chunksize=(20,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'labels.zarr' not in os.listdir('.'):\n",
    "    with open('annotations/instances_train2014.json','r') as file:\n",
    "        instances = json.load(file)\n",
    "    labels = np.array([category['name'] for category in instances['categories']])\n",
    "    labels = da.from_array(labels, chunks = (20))\n",
    "    labels.to_zarr('labels.zarr')\n",
    "    del instances\n",
    "\n",
    "labels = da.from_zarr('labels.zarr')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "if \"train_x_128_dask.zarr\" in os.listdir('.') and \"train_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        train_x = da.from_zarr(\"train_x_128_dask.zarr\")\n",
    "        train_y = da.from_zarr(\"train_y_dask.zarr\")\n",
    "\n",
    "else: \n",
    "    train_x = np.load('train_x_128.npy', allow_pickle=True)\n",
    "    train_x = train_x.astype('uint8')\n",
    "    train_x = da.from_array(train_x, chunks = (827,128,128,3))\n",
    "    train_x.to_zarr(\"train_x_128_dask.zarr\")\n",
    "    \n",
    "    train_y = np.load('train_y.npy', allow_pickle=True)\n",
    "    train_y = np.array(train_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels)\n",
    "    train_y = mlb.fit_transform(train_y)\n",
    "    \n",
    "    train_y = train_y.astype('uint8')\n",
    "    train_y = da.from_array(train_y, chunks = (827,128,128,3))\n",
    "    train_y.to_zarr(\"train_y_128_dask.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "if \"validation_x_128_dask.zarr\" in os.listdir('.') and \"validation_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        validation_x = da.from_zarr(\"validation_x_128_dask.zarr\")\n",
    "        validation_y = da.from_zarr(\"validation_y_dask.zarr\")\n",
    "\n",
    "else: \n",
    "    validation_x = np.load('validation_x_128.npy', allow_pickle=True)\n",
    "    validation_x = validation_x.astype('uint8')\n",
    "    validation_x = da.from_array(validation_x, chunks = (827,128,128,3))\n",
    "    validation_x.to_zarr(\"validation_x_128_dask.zarr\")\n",
    "    \n",
    "    validation_y = np.load('validation_y.npy', allow_pickle=True)\n",
    "    validation_y = np.array(validation_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels)\n",
    "    validation_y = mlb.fit_transform(validation_y)\n",
    "    \n",
    "    validation_y = validation_y.astype('uint8')\n",
    "    validation_y = da.from_array(validation_y, chunks = (827,128,128,3))\n",
    "    validation_y.to_zarr(\"validation_y_128_dask.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=25, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "if 'best_model.h5' in os.listdir():\n",
    "    model = load_model('best_model.h5')\n",
    "    model.load_weights('best_ modelw.h5')\n",
    "else:\n",
    "    model = ImageClassificationModel.build(target_size[0], target_size[1], len(labels), 'softmax')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.9, beta_2=0.95), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    stop_early = EarlyStopping(monitor='val_loss',patience = 20)\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',paitence = 20, factor=0.2, min_lr = 0.0001)\n",
    "    ModelCheck1 = ModelCheckpoint('best_model_loss.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    ModelCheck2 = ModelCheckpoint('best_model_acc.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks = [stop_early, reduceLR, ModelCheck1,ModelCheck2]\n",
    "    model.fit_generator(\n",
    "        train_datagen.flow(train_x, train_y, batch_size= batch_size),\n",
    "        steps_per_epoch = nb_train_samples//batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data=validation_datagen.flow(validation_x, validation_y, batch_size=batch_size),\n",
    "        validation_steps = nb_validation_samples//batch_size,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "model.save_weights(\"best_modelw.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9387c74797ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "evalue": "Error: connect ENOENT /var/folders/yw/sj6pnft95sd9bgslww298z8m0000gn/T/CoreFxPipe_vscode.47def194a6fbf0bac0fc1b8a33651666",
     "output_type": "error"
    }
   ],
   "source": [
    "img = Image.open('test/COCO_train2014_000000543689.jpg')# image extension *.png,*.jpg\n",
    "img.show()\n",
    "img = img.resize((128,128), Image.ANTIALIAS)\n",
    "arr = np.array(img)\n",
    "arr=np.expand_dims(arr,0)\n",
    "arr=arr/255\n",
    "proba = model.predict(arr)[0]\n",
    "proba= (proba*1000).astype(int)\n",
    "for x in range(len(proba)):\n",
    "    if proba[x] >100:\n",
    "        proba[x]=1\n",
    "    elif proba[x] > 50:\n",
    "        proba[x] = 0.5\n",
    "    else:\n",
    "        proba[x]=0\n",
    "for i in range(len(proba)):\n",
    "    if(proba[i]==1):\n",
    "        print(labels[i])\n",
    "    elif proba[i]==0.5:\n",
    "        print(\"Probably -> \", labels[i])"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}