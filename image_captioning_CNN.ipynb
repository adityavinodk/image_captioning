{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import dask.array as da\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.models import load_model\n",
    "from cnn_model import ImageClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (128,128)\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "nb_train_samples = len(os.listdir(train_data_dir))\n",
    "nb_validation_samples = len(os.listdir(validation_data_dir))\n",
    "epochs = 50\n",
    "batch_size = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('labels.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"train_x_128_dask.zarr\" in os.listdir('.') and \"train_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        train_x = da.from_zarr(\"train_x_128_dask.zarr\")\n",
    "        train_y = da.from_zarr(\"train_y_dask.zarr\")\n",
    "else: \n",
    "    print(\"Train dask arrays haven't been saved, please run extract_labels.py\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"validation_x_128_dask.zarr\" in os.listdir('.') and \"validation_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        train_x = da.from_zarr(\"validation_x_128_dask.zarr\")\n",
    "        train_y = da.from_zarr(\"validation_y_dask.zarr\")\n",
    "else: \n",
    "    print(\"Train dask arrays haven't been saved, please run extract_labels.py\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=25, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "if 'best_model.h5' in os.listdir() and 'best_ modelw.h5' in os.listdir():\n",
    "    model = load_model('best_model.h5')\n",
    "else:\n",
    "    model = ImageClassificationModel.build(target_size[0], target_size[1], len(labels), 'softmax')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.9, beta_2=0.95), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    stop_early = EarlyStopping(monitor='val_loss',patience = 20)\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',paitence = 20, factor=0.2, min_lr = 0.0001)\n",
    "    ModelCheck1 = ModelCheckpoint('best_model_loss.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    ModelCheck2 = ModelCheckpoint('best_model_acc.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "    callbacks = [stop_early, reduceLR, ModelCheck1,ModelCheck2]\n",
    "    model.fit_generator(\n",
    "        train_datagen.flow(train_x, train_y, batch_size= batch_size),\n",
    "        steps_per_epoch = nb_train_samples//batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data=validation_datagen.flow(validation_x, validation_y, batch_size=batch_size),\n",
    "        validation_steps = nb_validation_samples//batch_size,\n",
    "        callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"best_modelw.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of classes present\n",
      "person\n",
      "car\n",
      "bus\n",
      "traffic light\n",
      "handbag\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('test/COCO_train2014_000000543689.jpg')# image extension *.png,*.jpg\n",
    "img = img.resize((128,128), Image.ANTIALIAS)\n",
    "arr = np.array(img)\n",
    "arr=np.expand_dims(arr,0)\n",
    "arr=arr/255\n",
    "proba = testModel.predict(arr)[0]\n",
    "# print(proba)\n",
    "proba= (proba*1000).astype(int)\n",
    "for x in range(len(proba)):\n",
    "    if proba[x] >100:\n",
    "        proba[x]=1\n",
    "    elif proba[x] > 50:\n",
    "        proba[x] = 0.5\n",
    "    else:\n",
    "        proba[x]=0\n",
    "\n",
    "print('List of classes present')\n",
    "for i in range(len(proba)):\n",
    "    if(proba[i]==1):\n",
    "        print(labels[i])\n",
    "    elif proba[i]==0.5:\n",
    "        print(\"Probably -> \", labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
