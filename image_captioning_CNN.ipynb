{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\n"}],"source":"import os\nimport json\n\n# import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization, Input, Concatenate, AvgPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.regularizers import l1\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom cnn_model import ImageClassificationModel\n\n# import miscellaneous modules\nimport matplotlib.pyplot as plt\nfrom imutils import paths\nfrom six.moves import cPickle as pickle\nfrom PIL import Image\nimport cv2\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nimport shutil\nimport tarfile\nfrom multiprocessing import Manager, Process, Pool"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"with open('train_annotations.json', 'r') as file:\n    train_annotations = json.load(file)\n\nwith open('validation_annotations.json', 'r') as file:\n    validation_annotations = json.load(file)"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"target_size = (224,224)\ntrain_data_dir = 'train'\nvalidation_data_dir = 'validation'\nnb_train_samples = os.listdir('train')\nnb_validation_samples = os.listdir('validation')\nepochs = 50\nbatch_size = 32"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 49669/49669 [20:55<00:00, 39.55it/s]\n"}],"source":"imagePaths = list(paths.list_images('train'))\nshape = (len(imagePaths),)+target_size+(3,)\ntrain_x = np.zeros(shape=shape, dtype=np.float16)\ntrain_y = []\nfor i in tqdm(range(len(imagePaths))):\n    imagePath = imagePaths[i]\n    image = Image.open(imagePath)\n    image = image.resize(size=target_size, resample=Image.LANCZOS)\n    image = np.array(image)\n    if (len(image.shape) == 2):\n        image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n    # print(image.shape)\n    train_x[i]=image\n    labels = set()\n    for category in train_annotations[imagePath.split(os.path.sep)[-1]]['categories']: labels.add(category)\n    train_y.append(list(labels))"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":"print(train_x.shape)\ntrain_y = np.array(train_y)"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"0%|          | 0/100 [00:00<?, ?it/s]\n"},{"ename":"KeyError","evalue":"'COCO_train2014_000000339579.jpg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-49561e8d26ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_annotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimagePaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'COCO_train2014_000000339579.jpg'"]}],"source":"imagePaths = list(paths.list_images('validation'))\nshape = (len(imagePaths),)+target_size+(3,)\nvalidation_x = np.zeros(shape=shape, dtype=np.float16)\nvalidation_y = []\nfor i in tqdm(range(len(imagePaths))):\n    imagePath = imagePaths[i]\n    image = Image.open(imagePath)\n    image = image.resize(size=target_size, resample=Image.LANCZOS)\n    image = np.array(image)\n    if (len(image.shape) == 2):\n        image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n    # print(image.shape)\n    validation_x[i]=image\n    labels = set()\n    for category in validation_annotations[imagePaths[i].split(os.path.sep)[-1]]['categories']: labels.add(category)\n    validation_y.append(list(labels))"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7e744b953802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Information for training data - \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"]}],"source":"print(validation_x.shape)\nvalidation_y = np.array(validation_y)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"with open('instances_train2014.json','r') as file:\n    instances = json.load(file)\n\nlabels = np.array([category['name'] for category in instances['categories']])"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"train_datagen = ImageDataGenerator(\n        rotation_range=25, \n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        rescale=1./255,\n        shear_range=0.2,\n        fill_mode='nearest',\n        zoom_range=0.2,\n        horizontal_flip=True)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\nmodel = ImageClassificationModel.build(target_size[0], target_size[1], len(labels), 'softmax')\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.95), metrics=['accuracy'])"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"stop_early = EarlyStopping(monitor='val_loss', patience=3)\nreduceLR = ReduceLROnPlateau(monitor='val_loss', paitence = 1, factor=0.2, min_lr = 0.0001)\ncallbacks = [stop_early, reduceLR]\nmodel.fit_generator(\n    train_datagen.flow(train_x, train_y, batch_size= batch_size, target_size=target_size),\n    steps_per_epoch = nb_train_samples//batch_size,\n    validation_data=validation_datagen.flow(validation_x, validation_y, batch_size=batch_size, target_size=target_size),\n    validation_steps = nb_validation_samples//batch_size,\n    callbacks = callbacks)"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"img = Image.open('test/COCO_train2014_000000000109.jpg') # image extension *.png,*.jpg\nimg = img.resize((224,224), Image.ANTIALIAS)\narr = np.array(img)\narr=np.expand_dims(arr,0)\narr=arr/255\ntotal_model.predict(arr)"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}