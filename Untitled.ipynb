{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = da.from_zarr('labels.zarr')\n",
    "\n",
    "target_size = (128,128)\n",
    "test_data_dir = 'test'\n",
    "nb_test_samples = len(os.listdir(test_data_dir))\n",
    "epochs = 50\n",
    "batch_size = 60\n",
    "\n",
    "if \"best_model.h5\" in os.listdir():\n",
    "    model = load_model(\"best_model.h5\")\n",
    "\n",
    "if \"test_x_128_dask.zarr\" in os.listdir('.') and \"test_y_dask.zarr\" in os.listdir('.'):\n",
    "    with tf.device('/cpu:0'):\n",
    "        test_x = da.from_zarr(\"test_x_128_dask.zarr\")\n",
    "        test_y = da.from_zarr(\"test_y_dask.zarr\")\n",
    "\n",
    "elif 'test_x_128.npy' in os.listdir('.'): \n",
    "    test_x = np.load('test_x_128.npy', allow_pickle=True)\n",
    "    test_x = test_x.astype('uint8')\n",
    "    test_x = da.from_array(test_x, chunks = (827,128,128,3))\n",
    "    test_x.to_zarr(\"test_x_128_dask.zarr\")\n",
    "    \n",
    "    test_y = np.load('test_y.npy', allow_pickle=True)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels.compute())\n",
    "    test_y = mlb.fit_transform(test_y)\n",
    "    \n",
    "    test_y = test_y.astype('uint8')\n",
    "    test_y = da.from_array(test_y, chunks = (827))\n",
    "    test_y.to_zarr(\"test_y_dask.zarr\")\n",
    "else:\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "    from imutils import paths\n",
    "    with open('test_annotations.json', 'r') as file:\n",
    "        test_annotations = json.load(file )\n",
    "    imagePaths = list(paths.list_images('test'))\n",
    "    shape = (len(imagePaths),)+target_size+(3,)\n",
    "    test_x = np.zeros(shape=shape, dtype=np.float16)\n",
    "    test_y = []\n",
    "    for i in tqdm(range(len(imagePaths))):\n",
    "        imagePath = imagePaths[i]\n",
    "        image = Image.open(imagePath)\n",
    "        image = image.resize(size=target_size, resample=Image.LANCZOS)\n",
    "        image = np.array(image)\n",
    "        if (len(image.shape) == 2):\n",
    "            image = np.repeat(image[:, :, np.newaxis], 3, axis=2)\n",
    "        # print(image.shape)\n",
    "        test_x[i]=image\n",
    "        labels = set()\n",
    "        for category in test_annotations[imagePath.split(os.path.sep)[-1]]['categories']: labels.add(category)\n",
    "        test_y.append(list(labels))\n",
    "    np.save(\"test_x_128.npy\",test_x)\n",
    "    np.save(\"test_y.npy\",test_y)\n",
    "    test_x = test_x.astype('uint8')\n",
    "    test_x = da.from_array(test_x, chunks = (827,128,128,3))\n",
    "    test_x.to_zarr(\"test_x_128_dask.zarr\")\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    mlb = MultiLabelBinarizer(labels)\n",
    "    test_y = mlb.fit_transform(test_y)\n",
    "    \n",
    "    test_y = test_y.astype('uint8')\n",
    "    test_y = da.from_array(test_y, chunks = (827,128,128,3))\n",
    "    test_y.to_zarr(\"test_y_128_dask.zarr\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    stop_early = EarlyStopping(monitor='val_loss',patience = 20)\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss',paitence = 20, factor=0.2, min_lr = 0.0001)\n",
    "    ModelCheck = ModelCheckpoint('best_model_loss.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "    callbacks = [stop_early, reduceLR, ModelCheck]\n",
    "    scores = model.evaluate_generator(\n",
    "        test_datagen.flow(test_x, test_y, batch_size=batch_size),\n",
    "        steps = nb_test_samples//batch_size,\n",
    "        callbacks = callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.700784161307595, 0.4498182]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
